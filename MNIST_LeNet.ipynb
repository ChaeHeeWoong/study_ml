{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda activate : True\n",
      "\n",
      "python_version : 3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]\n",
      "\n",
      "torch_version : 1.12.1\n",
      "\n",
      "cuda_version : 11.6\n",
      "\n",
      "cudnn_version : 8302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"cuda activate : {torch.cuda.is_available()}\\n\") #gpu\n",
    "print(f\"python_version : {sys.version}\\n\") #python\n",
    "print(f\"torch_version : {torch.__version__}\\n\") #pytorch\n",
    "print(f\"cuda_version : {torch.cuda_version}\\n\") #cuda\n",
    "print(f\"cudnn_version : {torch.backends.cudnn.version()}\\n\") #cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Administrator\\\\Desktop\\\\study\\\\lecture\\\\Part 5\\\\Untitled Folder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "os.getcwd() #디렉토리 확인\n",
    "#sys.path.append('') #필요 lib나 링크 추가할 때 쓰는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import RAdam\n",
    "\n",
    "import wandb\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "#prepare to download data\n",
    "#NLP data는 다름\n",
    "data_root = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5]),\n",
    "    ]\n",
    ")\n",
    "fashion_mnist_dataset = FashionMNIST(data_root, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loads the data\"\"\"\n",
    "# Create indices for the split\n",
    "batch_size=100\n",
    "\n",
    "dataset_size = len(fashion_mnist_dataset)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(fashion_mnist_dataset,\n",
    "                                               [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waarmup Scheduler\n",
    "\n",
    "class WarmupLR(optim.lr_scheduler.LambdaLR) :\n",
    "    def __init__ (\n",
    "        self, \n",
    "        optimizer:optim.Optimizer,\n",
    "        warmup_end_steps: int,\n",
    "        last_epoch : int = -1,    \n",
    "        ):\n",
    "\n",
    "        def warmup_fn(step: int):\n",
    "            if step < warmup_end_steps:\n",
    "                return float(step) / float(max(warmup_end_steps,1))\n",
    "            return 1.0\n",
    "\n",
    "        super().__init__(optimizer, warmup_fn, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.ckpt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        \n",
    "        filename = self.path.split('/')[-1]\n",
    "        save_dir = os.path.dirname(self.path)\n",
    "        print(save_dir, f\"val_loss-{val_loss}-{filename}\")\n",
    "        torch.save(model, f = os.path.join(save_dir, f\"val_loss-{val_loss}\"))\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\tdef __init__(self, numChannels, classes):\n",
    "\t\tsuper(LeNet, self).__init__()\n",
    "\t\t#Layer1\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=numChannels, out_channels=20,kernel_size=(5, 5))\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t#Layer2\n",
    "\t\tself.conv2 = nn.Conv2d(in_channels=20, out_channels=50,kernel_size=(5, 5))\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\t\tself.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\tself.fc1 = nn.Linear(in_features=800, out_features=500)\n",
    "\t\tself.relu3 = nn.ReLU()\n",
    "\t\tself.fc2 = nn.Linear(in_features=500, out_features=classes)\n",
    "\t\tself.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "\t\tx = torch.flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu3(x)\n",
    "\t\t# pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "\t\tx = self.fc2(x)\n",
    "\t\toutput = self.logSoftmax(x)\n",
    "\t\t# return the output predictions\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmagicturtle\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Administrator\\Desktop\\study\\lecture\\Part 5\\Untitled Folder\\wandb\\run-20220925_153919-3799qexl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/magicturtle/fashion_mnist_tutorials/runs/3799qexl\" target=\"_blank\">2022-09-25 1539-LeNet-RAdam_optim_0.001_lr_with_WarmupLR_scheduler</a></strong> to <a href=\"https://wandb.ai/magicturtle/fashion_mnist_tutorials\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs\\2022-09-25 1539-LeNet\\models\n"
     ]
    }
   ],
   "source": [
    "#define model.\n",
    "# crtl + slash => 주석 한번에 달기\n",
    "#model = MLP(28*28, 128, 64, 10)\n",
    "#model = MLPWithDropout(28*28, 256,128, 64, 10, dropout_prob=0.3)\n",
    "\n",
    "model = LeNet(1,len(fashion_mnist_dataset.classes))\n",
    "model_name = type(model).__name__\n",
    "\n",
    "#define loss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#define optimizer\n",
    "lr = 1e-3\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = RAdam(model.parameters(), lr=lr)\n",
    "optimizer_name = type(optimizer).__name__\n",
    "\n",
    "#define scheduler\n",
    "scheduler = WarmupLR(optimizer, 1500)\n",
    "scheduler_name = type(scheduler).__name__ if scheduler is not None else \"No\"\n",
    "\n",
    "max_epoch = 100\n",
    "\n",
    "#define tensorboard logger\n",
    "#log_dir = os.path.join(\"runs\", model_name)\n",
    "\n",
    "now = datetime.now()\n",
    "run_name = f\"{now.strftime('%Y-%m-%d %H%M')}-{model_name}-{optimizer_name}_optim_{lr}_lr_with_{scheduler_name}_scheduler\" \n",
    "log_dir = f\"runs\\{now.strftime('%Y-%m-%d %H%M')}-{model_name}\"\n",
    "\n",
    "log_interval = 100\n",
    "\n",
    "#define wandb\n",
    "\n",
    "project_name = \"fashion_mnist_tutorials\"\n",
    "run_tags = [project_name]\n",
    "wandb.init(\n",
    "    project = project_name,\n",
    "    name= run_name,\n",
    "    tags= run_tags,\n",
    "    config={\"lr\" : lr, \"model_name\" : model_name, \"optimizer_name\" : optimizer_name , \"scheduler_name\" : scheduler_name},\n",
    "    reinit=True\n",
    "\n",
    ")\n",
    "\n",
    "#save model path+\n",
    "log_model_path = os.path.join(log_dir, \"models\")\n",
    "os.makedirs(log_model_path, exist_ok=True)\n",
    "print(log_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch, 0 step: val_loss : 0.023053469136357307, val_acc: 0.10233331471681595\n",
      "Validation loss decreased (inf --> 0.023053).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.023053469136357307-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 1/540 [00:00<00:56,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : train_loss : 0.023037714958190916, train_acc: 0.07000000029802322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▉        | 103/540 [00:06<00:27, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 : train_loss : 0.022528088092803954, train_acc: 0.3700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  38%|███▊      | 203/540 [00:11<00:19, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 : train_loss : 0.015557587146759033, train_acc: 0.5299999713897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 303/540 [00:17<00:14, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 : train_loss : 0.008455737829208373, train_acc: 0.7699999809265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  75%|███████▍  | 403/540 [00:23<00:08, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 : train_loss : 0.007424333095550537, train_acc: 0.7099999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  93%|█████████▎| 503/540 [00:28<00:02, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 : train_loss : 0.0067047041654586794, train_acc: 0.7400000095367432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.46it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch, 540 step: val_loss : 0.006023855414241552, val_acc: 0.783333420753479\n",
      "Validation loss decreased (0.023053 --> 0.006024).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.006023855414241552-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  11%|█▏        | 62/540 [00:03<00:29, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 : train_loss : 0.004999824464321136, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███       | 162/540 [00:09<00:22, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 : train_loss : 0.003843148052692413, train_acc: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  49%|████▊     | 262/540 [00:14<00:16, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 : train_loss : 0.004501811563968659, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 362/540 [00:20<00:10, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 : train_loss : 0.006816683411598206, train_acc: 0.7699999809265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 462/540 [00:25<00:04, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 : train_loss : 0.0047094601392745974, train_acc: 0.7599999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:29<00:00, 18.02it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch, 1080 step: val_loss : 0.004098251927644014, val_acc: 0.8528333902359009\n",
      "Validation loss decreased (0.006024 --> 0.004098).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.004098251927644014-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|▍         | 24/540 [00:01<00:30, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 : train_loss : 0.0030907675623893737, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  23%|██▎       | 122/540 [00:06<00:24, 16.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 : train_loss : 0.004264865219593048, train_acc: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  41%|████      | 222/540 [00:12<00:19, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 : train_loss : 0.0031796783208847047, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  60%|█████▉    | 322/540 [00:17<00:13, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 : train_loss : 0.0039352202415466305, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  78%|███████▊  | 422/540 [00:23<00:06, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 : train_loss : 0.003869321346282959, train_acc: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  97%|█████████▋| 522/540 [00:29<00:01, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 : train_loss : 0.003529263436794281, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.93it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 32.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch, 1620 step: val_loss : 0.003430720651522279, val_acc: 0.880500078201294\n",
      "Validation loss decreased (0.004098 --> 0.003431).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.003430720651522279-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  15%|█▌        | 82/540 [00:04<00:27, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 : train_loss : 0.0033295288681983947, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▎      | 182/540 [00:10<00:21, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 : train_loss : 0.0037847697734832765, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  52%|█████▏    | 282/540 [00:15<00:15, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 : train_loss : 0.002346283197402954, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  71%|███████   | 382/540 [00:21<00:09, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 : train_loss : 0.0028591197729110718, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  89%|████████▉ | 482/540 [00:26<00:03, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 : train_loss : 0.003328206539154053, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.95it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch, 2160 step: val_loss : 0.00316341663710773, val_acc: 0.887666642665863\n",
      "Validation loss decreased (0.003431 --> 0.003163).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.00316341663710773-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   8%|▊         | 42/540 [00:02<00:30, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 : train_loss : 0.0025324925780296327, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  26%|██▋       | 142/540 [00:07<00:24, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 : train_loss : 0.002506676912307739, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  45%|████▍     | 242/540 [00:13<00:17, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 : train_loss : 0.0019700668752193453, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  63%|██████▎   | 342/540 [00:19<00:12, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 : train_loss : 0.0033212104439735413, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  82%|████████▏ | 442/540 [00:24<00:05, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 : train_loss : 0.002803739011287689, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.95it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch, 2700 step: val_loss : 0.002749453531578183, val_acc: 0.9023332595825195\n",
      "Validation loss decreased (0.003163 --> 0.002749).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.002749453531578183-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 2/540 [00:00<00:41, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 : train_loss : 0.0018758703768253326, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▉        | 102/540 [00:05<00:26, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800 : train_loss : 0.002101212739944458, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  37%|███▋      | 202/540 [00:11<00:20, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 : train_loss : 0.0030521559715270996, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 302/540 [00:16<00:14, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 : train_loss : 0.0018886443972587585, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  74%|███████▍  | 402/540 [00:22<00:08, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100 : train_loss : 0.002500273287296295, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  93%|█████████▎| 502/540 [00:27<00:02, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200 : train_loss : 0.002037038654088974, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.96it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch, 3240 step: val_loss : 0.002697484102100134, val_acc: 0.9058332443237305\n",
      "Validation loss decreased (0.002749 --> 0.002697).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.002697484102100134-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  11%|█▏        | 62/540 [00:03<00:28, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 : train_loss : 0.0019606977701187136, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███       | 162/540 [00:09<00:22, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400 : train_loss : 0.0029105913639068605, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  49%|████▊     | 262/540 [00:14<00:16, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500 : train_loss : 0.0035282608866691587, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 362/540 [00:20<00:10, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 : train_loss : 0.00183489128947258, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 462/540 [00:25<00:04, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700 : train_loss : 0.0008021567016839981, train_acc: 0.9800000190734863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.94it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch, 3780 step: val_loss : 0.002689993241801858, val_acc: 0.902166485786438\n",
      "Validation loss decreased (0.002697 --> 0.002690).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.002689993241801858-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|▍         | 22/540 [00:01<00:31, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800 : train_loss : 0.0015316396951675416, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  23%|██▎       | 122/540 [00:06<00:26, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900 : train_loss : 0.0014938491582870484, train_acc: 0.9599999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  41%|████      | 222/540 [00:12<00:19, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 : train_loss : 0.0017315521836280823, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  60%|█████▉    | 322/540 [00:17<00:13, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100 : train_loss : 0.001215102970600128, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  78%|███████▊  | 422/540 [00:23<00:07, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 : train_loss : 0.0021927472949028015, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  97%|█████████▋| 522/540 [00:29<00:01, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300 : train_loss : 0.0016269780695438384, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.96it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch, 4320 step: val_loss : 0.0027117463760077953, val_acc: 0.9059999585151672\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  15%|█▌        | 82/540 [00:04<00:28, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 : train_loss : 0.0014993767440319061, train_acc: 0.9599999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▎      | 182/540 [00:10<00:21, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 : train_loss : 0.0012775886058807374, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  52%|█████▏    | 282/540 [00:15<00:15, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600 : train_loss : 0.0009701609611511231, train_acc: 0.9700000286102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  71%|███████   | 382/540 [00:21<00:09, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700 : train_loss : 0.0016563217341899871, train_acc: 0.9599999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  89%|████████▉ | 482/540 [00:26<00:03, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 : train_loss : 0.002324609011411667, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.95it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 32.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epoch, 4860 step: val_loss : 0.0025349785573780537, val_acc: 0.9100000262260437\n",
      "Validation loss decreased (0.002690 --> 0.002535).  Saving model ...\n",
      "runs\\2022-09-25 1539-LeNet\\models val_loss-0.0025349785573780537-runs\\2022-09-25 1539-LeNet\\models\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   8%|▊         | 42/540 [00:02<00:30, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 : train_loss : 0.0020996886491775513, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  26%|██▋       | 142/540 [00:07<00:24, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 : train_loss : 0.001535397171974182, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  45%|████▍     | 242/540 [00:13<00:17, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 : train_loss : 0.0019870419800281525, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  63%|██████▎   | 342/540 [00:18<00:12, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 : train_loss : 0.00149045929312706, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  82%|████████▏ | 442/540 [00:24<00:05, 16.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 : train_loss : 0.002000833749771118, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:29<00:00, 18.01it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 31.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 epoch, 5400 step: val_loss : 0.0026074585039168596, val_acc: 0.9079998731613159\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 2/540 [00:00<00:39, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 : train_loss : 0.0014562013745307923, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▉        | 102/540 [00:05<00:26, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500 : train_loss : 0.0005703501775860786, train_acc: 0.9800000190734863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  37%|███▋      | 202/540 [00:11<00:20, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600 : train_loss : 0.0018944093585014344, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 302/540 [00:16<00:14, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700 : train_loss : 0.0017930692434310913, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  74%|███████▍  | 402/540 [00:22<00:08, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 : train_loss : 0.0011047585308551788, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  93%|█████████▎| 502/540 [00:28<00:02, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900 : train_loss : 0.0020732849836349486, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.92it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 32.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 epoch, 5940 step: val_loss : 0.0027158299926668406, val_acc: 0.9111667275428772\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  11%|█▏        | 62/540 [00:03<00:28, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 : train_loss : 0.0010173135995864867, train_acc: 0.9700000286102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███       | 162/540 [00:09<00:22, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100 : train_loss : 0.0006374160945415496, train_acc: 0.9700000286102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  49%|████▊     | 262/540 [00:14<00:16, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200 : train_loss : 0.0013257345557212829, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 362/540 [00:20<00:10, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300 : train_loss : 0.0012345672398805618, train_acc: 0.9599999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 462/540 [00:25<00:04, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 : train_loss : 0.001049957573413849, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:30<00:00, 17.98it/s]\n",
      "validation: 100%|██████████| 60/60 [00:01<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 epoch, 6480 step: val_loss : 0.002735863672569394, val_acc: 0.9144998788833618\n",
      "EarlyStopping counter: 3 out of 3\n"
     ]
    }
   ],
   "source": [
    "#define early stopping\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=3, verbose=True, path= os.path.join(log_model_path,\"model.ckpt\")\n",
    ")\n",
    "\n",
    "train_step = 0\n",
    "for epoch in range(1, max_epoch+1):\n",
    "    #validation step\n",
    "    #validation 할 때 optimizer가 train에 관여하지 않도록 해야 함\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects =0\n",
    "        model.eval()\n",
    "        \n",
    "        for val_batch_idx, (val_images, val_labels) in enumerate (\n",
    "            tqdm(val_loader, position=0, leave=True, desc = \"validation\") #중간중간 output을 예쁘게 보이게\n",
    "        ):\n",
    "            # forwards\n",
    "            val_outputs = model(val_images)\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "\n",
    "            # loss & acc\n",
    "            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0] #val_outputs.shape는 batchsize\n",
    "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
    "     \n",
    "    #vaild step logging\n",
    "    val_epoch_loss = val_loss / len(val_loader)\n",
    "    val_epoch_acc = val_corrects / len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"{epoch} epoch, {train_step} step: val_loss : {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n",
    "        )\n",
    "    \n",
    "    #wandb log\n",
    "    wandb.log({\n",
    "        \"Loss/val\": val_epoch_loss,\n",
    "        \"Acc/val\" : val_epoch_acc,\n",
    "        \"Images/val\" : wandb.Image(val_images),\n",
    "        \"Preds/val\" : wandb.Histogram(val_outputs.detach().numpy()),\n",
    "        \"Outputs/val\" : wandb.Histogram(val_preds.detach().numpy()),\n",
    "        \"Labels/val\" : wandb.Histogram(val_labels.data.detach().numpy()),\n",
    "        }\n",
    "        , step=train_step\n",
    "    )\n",
    "\n",
    "    #check model early stopping poing & save model if model reached the best performance.\n",
    "    early_stopper(val_epoch_loss, model)\n",
    "    if early_stopper.early_stop :\n",
    "        break\n",
    "\n",
    "    current_loss = 0\n",
    "    current_correct= 0 \n",
    "    model.train()\n",
    "\n",
    "\n",
    "    #train step    \n",
    "    for batch_idx, (images, labels) in enumerate(\n",
    "        tqdm(train_loader, position=0, leave=True, desc = \"train\") #중간중간 output을 예쁘게 보이게\n",
    "    ):\n",
    "        \n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "        \n",
    "        #forwards\n",
    "        #get predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "      \n",
    "        #get loss (Loss 계산)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        #backpropagation\n",
    "        #opmizier 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform Optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Perform Scheduler\n",
    "        if scheduler is not None :\n",
    "           scheduler.step()\n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        current_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        if train_step % log_interval == 0:\n",
    "           train_loss = current_loss / log_interval\n",
    "           train_acc = current_corrects / log_interval\n",
    "            \n",
    "           print(\n",
    "                    f\"{train_step} : train_loss : {train_loss}, train_acc: {train_acc}\"\n",
    "            )\n",
    "\n",
    "           # wandb log \n",
    "           wandb.log({\n",
    "           \"Loss/train\": train_loss,\n",
    "           \"Acc/train\" : train_acc,\n",
    "           \"Images/train\" : wandb.Image(val_images),\n",
    "           \"Preds/train\" : wandb.Histogram(outputs.detach().numpy()),\n",
    "           \"Outputs/train\" : wandb.Histogram(preds.detach().numpy()),\n",
    "           \"Labels/train\" : wandb.Histogram(labels.data.detach().numpy()),\n",
    "           \"Leanring Rate\" : scheduler.get_last_lr()[0]\n",
    "           }\n",
    "            , step=train_step\n",
    "           )\n",
    "           current_loss = 0\n",
    "           current_correct= 0 \n",
    "            \n",
    "        train_step +=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "os.makedirs(\"./logs/models\", exist_ok=True)\n",
    "torch.save(model, os.path.join(log_model_path, \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (logSoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "loaded_model = torch.load(os.path.join(log_model_path,\"val_loss-0.0025349785573780537\"))\n",
    "loaded_model.eval()\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"numpy softmax\"\n",
    "    max = np.max(x, axis=axis, keepdims=True)\n",
    "    e_x = np.exp(x-max)\n",
    "    sum = np.sum(e_x, axis=axis, keepdims=True)\n",
    "    f_x = e_x / sum\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 100/100 [00:03<00:00, 29.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 84.13000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test dataset download\n",
    "test_batch_size = 100\n",
    "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size= test_batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "test_labels_list = []\n",
    "test_preds_list = []\n",
    "test_outputs_list = []\n",
    "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc = \"testing\")):\n",
    "    #forward\n",
    "    test_outputs = loaded_model(test_images)\n",
    "    _, test_preds = torch.max(test_outputs,1)\n",
    "\n",
    "    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n",
    "    test_outputs_list.extend(final_outs)\n",
    "    test_preds_list.extend(test_preds.detach().numpy()) #gpu로 연산한 데이터는 넘파이로 사용할 때 반드시 detach로 풀어써줘서 cpu로 옮겨줘야함\n",
    "    test_labels_list.extend(test_labels.detach().numpy()) #gpu로 연산한 데이터는 넘파이로 사용할 때 반드시 detach로 풀어써줘서 cpu로 옮겨줘야함\n",
    "    \n",
    "\n",
    "test_preds_list = np.array(test_preds_list) #acc를 구하기 위해 numpy로 바꿔\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "print(f\"acc: {np.mean(test_preds_list == test_labels_list)*100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b09f0dae079356b11e2992c8ce1698bd60fda55aea4c87f004ec164747e9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
